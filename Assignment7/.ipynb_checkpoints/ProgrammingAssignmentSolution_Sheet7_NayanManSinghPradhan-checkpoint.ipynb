{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Sheet 7\n",
    "## Done by Nayan Man Singh Pradhan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming exercise, you will implement the validation set approach and K-fold cross validation, while recalling that leave-one-out cross validation is K-fold cross validation for K = N , if N is the number of training samples. Implement the study carried out in Example 6.3 from the lecture notes. Note that due to randomization, you might get other results than the ones shown in the example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## L2 Loss function\n",
    "def L2_loss(pred, actual):\n",
    "    return (pred-actual)**2\n",
    "    \n",
    "#------------------------------------------------------------------------------------------#\n",
    "    \n",
    "## Error estimation by validation set approach for graphing\n",
    "def err_validation_set_graph(train_x, train_y, validate_x, validate_y, k_for_KNN_reg):\n",
    "    \n",
    "    ## Using KNN regressor to predict for single k\n",
    "    clf = KNeighborsRegressor(n_neighbors = k_for_KNN_reg)\n",
    "    clf.fit(train_x, train_y)\n",
    "    prediction = (clf.predict(validate_x))\n",
    "    Err = (1/len(validate_x)) * sum(L2_loss(prediction, validate_y))\n",
    "\n",
    "    return Err\n",
    "\n",
    "#------------------------------------------------------------------------------------------#\n",
    "\n",
    "## Error estimation by validation set approach\n",
    "def err_validation_set(x, y, k_for_KNN_reg):\n",
    "    \n",
    "    ## Splitting data into train and validate sets\n",
    "    split_size = random.randint(1, len(x)-1)\n",
    "    train_x = x[0:split_size]\n",
    "    train_y = y[0:split_size]\n",
    "    validate_x = x[split_size:]\n",
    "    validate_y = y[split_size:]\n",
    "    \n",
    "    ## Reshaping into np array\n",
    "    train_x = np.array(train_x)\n",
    "    validate_x = np.array(validate_x)\n",
    "    train_x = train_x.reshape(-1,1)\n",
    "    validate_x = validate_x.reshape(-1,1)\n",
    "    \n",
    "    ## Using KNN regressor to predict for single k\n",
    "    clf = KNeighborsRegressor(n_neighbors = k_for_KNN_reg)\n",
    "    clf.fit(train_x, train_y)\n",
    "    prediction = (clf.predict(validate_x))\n",
    "    Err = (1/len(validate_x)) * sum(L2_loss(prediction, validate_y))\n",
    "\n",
    "    return Err[0]\n",
    "\n",
    "#------------------------------------------------------------------------------------------#\n",
    "\n",
    "## Error estimation by k fold cross validation\n",
    "def k_fold_cross_validation(x, y, k_folds, k_for_KNN_reg):\n",
    "    inp = list(zip(x, y))\n",
    "    folds = np.array_split(inp, k_folds)\n",
    "    \n",
    "    Err = []\n",
    "    \n",
    "    for i in range(0, len(folds)):\n",
    "        x_Train = []\n",
    "        y_Train = []\n",
    "        x_Validate = []\n",
    "        y_Validate = []\n",
    "        Validate = []\n",
    "        \n",
    "        Validate.append(folds[i])\n",
    "        Train = [z for j, z in enumerate(folds) if j!=i]\n",
    "        \n",
    "        for train_datas in Train:\n",
    "            for train_data in train_datas:\n",
    "                x_Train.append(train_data[0])\n",
    "                y_Train.append(train_data[1])\n",
    "                \n",
    "        for validate_datas in Validate:\n",
    "            for validate_data in validate_datas:\n",
    "                x_Validate.append(validate_data[0])\n",
    "                y_Validate.append(validate_data[1])\n",
    "\n",
    "        x_Train = np.asarray(x_Train)\n",
    "        y_Train = np.asarray(y_Train)\n",
    "        x_Validate = np.asarray(x_Validate)\n",
    "        y_Validate = np.asarray(y_Validate)\n",
    "\n",
    "        x_Train = x_Train.reshape(-1, 1)\n",
    "        y_Train = y_Train.reshape(-1, 1)        \n",
    "        x_Validate = x_Validate.reshape(-1, 1)\n",
    "        y_Validate = y_Validate.reshape(-1, 1)\n",
    "        \n",
    "        clf = KNeighborsRegressor(n_neighbors = k_for_KNN_reg)\n",
    "        clf.fit(x_Train, y_Train)\n",
    "        prediction = (clf.predict(x_Validate))\n",
    "        Err.append((1/len(x_Validate)) * sum(L2_loss(prediction, y_Validate)))\n",
    "    \n",
    "    Avg_Err = (1/k_folds) * sum(sum(Err))\n",
    "    \n",
    "    return (Avg_Err)\n",
    "\n",
    "#------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k_for_knn_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8fdc8b87de65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m## Error in validation set for K_neighbors = 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0merr_val_set_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr_validation_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_for_knn_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m## Error in k-fold validtiaon set for K_neighbors = 3 and K_folds = 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k_for_knn_reg' is not defined"
     ]
    }
   ],
   "source": [
    "## Results\n",
    "\n",
    "## Generate random input sample\n",
    "N = 51\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, N):\n",
    "    mu, sigma = 0, 1.15 ## mean and standard deviation\n",
    "    noise = np.random.normal(mu, sigma, 1)\n",
    "    \n",
    "    temp_x = random.randint(-4,4)\n",
    "    temp_y = temp_x**2 + noise\n",
    "    \n",
    "    x.append(temp_x)\n",
    "    y.append(temp_y)\n",
    "    \n",
    "k_for_knn_reg = 3\n",
    "\n",
    "## Error in validation set for K_neighbors = 3\n",
    "err_val_set_result = err_validation_set(x, y, k_for_knn_reg)\n",
    "\n",
    "k_folds = 10\n",
    "## Error in k-fold validtiaon set for K_neighbors = 3 and K_folds = 10\n",
    "k_fold_result = k_fold_cross_validation(x, y, k_folds, k_for_knn_reg)\n",
    "\n",
    "print(\"From Error Validation Set:\", err_val_set_result)\n",
    "print(\"From K-fold Validation Set:\", k_fold_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For graphing like example 6.3\n",
    "\n",
    "## Generate random input sample\n",
    "N = 51\n",
    "x = []\n",
    "y = []\n",
    "for i in range(0, N):\n",
    "    mu, sigma = 0, 1.15 ## mean and standard deviation\n",
    "    noise = np.random.normal(mu, sigma, 1)\n",
    "    \n",
    "    temp_x = random.randint(-4,4)\n",
    "    temp_y = temp_x**2 + noise\n",
    "    \n",
    "    x.append(temp_x)\n",
    "    y.append(temp_y)\n",
    "    \n",
    "## Splitting data into train and validate sets\n",
    "split_size = random.randint(1, len(x)-1)\n",
    "train_x = x[0:split_size]\n",
    "train_y = y[0:split_size]\n",
    "validate_x = x[split_size:]\n",
    "validate_y = y[split_size:]\n",
    "    \n",
    "## Reshaping into np array\n",
    "train_x = np.array(train_x)\n",
    "validate_x = np.array(validate_x)\n",
    "train_x = train_x.reshape(-1,1)\n",
    "validate_x = validate_x.reshape(-1,1)\n",
    "    \n",
    "## Error Validation Set     \n",
    "for k in range(len(train_x), 0, -1):\n",
    "    result_validation_set_graph = err_validation_set_graph(train_x, train_y, validate_x, validate_y, k)\n",
    "    plt.plot(k, result_validation_set_graph, color = 'c', label=\"knn regressor\")\n",
    "    plt.plot(k, result_validation_set_graph, 'rs', markersize=10, color = 'r')\n",
    "    plt.title(\"neighborhood size k vs generalization error\")\n",
    "    plt.xlabel(\"neighborhood size k\")\n",
    "    plt.ylabel(\"generalization error\")\n",
    "plt.show()\n",
    "print(\"We notice that the generalization error is the minimum when the neighborhood size is small, and is large when the neighboorhood size is large.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
