{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.linalg as linalg\n",
    "from sklearn import linear_model\n",
    "from matplotlib import cm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "\n",
    "## Cholesky equation solver\n",
    "def Cholesky_solver(M, b):\n",
    "    c, low = linalg.cho_factor(M)\n",
    "    return (linalg.cho_solve((c, low), b))\n",
    "\n",
    "## For solving linear equation\n",
    "def linear_eqn_solver(m, X, c):\n",
    "    return (np.dot(X, m) + c)\n",
    "    \n",
    "## Main linear regression\n",
    "def lin_reg(x, y, test):\n",
    "    \n",
    "    ## Build matrix X\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    x_of1 = np.ones((x.shape[0], 1))\n",
    "    X = np.hstack((x_of1, x))\n",
    "    \n",
    "    ## b <-- X.T y\n",
    "    b = np.dot(X.T, y)\n",
    "    \n",
    "    ## A <-- X.T X\n",
    "    A = np.dot(X.T, X)\n",
    "    \n",
    "    ## Solve AB = b using Cholesky factorization\n",
    "    B_hat = Cholesky_solver(A, b)\n",
    "    \n",
    "    ## Predict\n",
    "    lin_reg_pred = linear_eqn_solver(B_hat[1:], test, B_hat[0])\n",
    "    \n",
    "    return lin_reg_pred, B_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(x, y, test):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    x_of1 = np.ones((x.shape[0], 1))\n",
    "    X = np.hstack((x_of1, x))\n",
    "\n",
    "    nabla_B = lin_reg(x, y, test)[1]\n",
    "    output = -2*(np.dot(X.T, (y-np.dot(X,nabla_B))))\n",
    "    return (output)\n",
    "    \n",
    "def minibatch_gradient_descent(x, y, test, initial_guess, batch_size, learning_rate, tolerance):\n",
    "    n = 0\n",
    "    w_n = initial_guess\n",
    "    while(np.linalg.norm(J(x, y, test)) < tolerance):\n",
    "        mini_batches = np.split(X, (len(X)/batch_size))\n",
    "        random_num_in_mini_batches = random.randint(0, len(mini_batches))\n",
    "#         mini_range = random.randrange(x[0], x[-1], batch_size)\n",
    "        mini_batches = []\n",
    "        print(mini_batch)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[array([[0],\n",
      "       [1],\n",
      "       [2]]), array([[3],\n",
      "       [4]])]\n"
     ]
    }
   ],
   "source": [
    "X = [[0], [1], [2], [3], [4]]\n",
    "y = [0, 0.3, 0.75, 1, 2]\n",
    "\n",
    "test = np.array([3])\n",
    "test = test.reshape(-1, 1)\n",
    "\n",
    "# print(J(X,y,test))\n",
    "\n",
    "# temp_batch = random.randrange(X[0], X[-1], 3)\n",
    "# print(temp_batch)\n",
    "X = np.asarray(X)\n",
    "\n",
    "print(len(np.split(X, (len(X)/3))))\n",
    "\n",
    "# plt.plot(X, y, color = 'c')\n",
    "# plt.plot(X,y, 'rs', color = 'c', markersize=12, label=\"trainin set\")\n",
    "# plt.title(\"Using Self Implemented Function\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
