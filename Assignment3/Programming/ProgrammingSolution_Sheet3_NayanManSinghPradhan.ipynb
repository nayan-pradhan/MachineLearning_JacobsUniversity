{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Sheet 3\n",
    "## Done by Nayan Man Singh Pradhan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Approach Explained:\n",
    "- I downloaded all the documents in website: https://archive.ics.uci.edu/ml/datasets/spambase.\n",
    "- I loaded the data from the \"spambase.data\" file.\n",
    "- I used Linear Regression, SVC, and KNN to create a Pipeline that predicts whether the email is Spam or Not Spam based on the loaded data from the \"spambase.data\" file.\n",
    "- I picked the classifier with the best accuracy (SVC) in order to predict any test email as Spam or Not Spam based on the trained input data.\n",
    "- I loaded the example spam emails.\n",
    "- I extracted the required 57 attributes.\n",
    "- I printed the 57 attributes into the file: \"only_all_attributes.txt\".\n",
    "- I predicted whether the example was Spam or Not Spam based on the trained pipeline (SVC).\n",
    "- I printed the total vector or 57 attributes + spam or not spam class = 58 into the file: \"attributes+prediction_output.txt\" file.\n",
    "- I tested the example mail + an extra test email (just for testing purpose)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  57  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading data\n",
    "raw_data = pd.read_csv('spambase.data', sep=',', header=None)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Data using different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function that turns float prediction to binary (only for linear regression)\n",
    "def predict_binary(raw_out):\n",
    "    if (raw_out < 0.5):\n",
    "        return \"0\"\n",
    "    else:\n",
    "        return \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X and y\n",
    "X = np.array(raw_data.drop(raw_data.columns[57], 1))\n",
    "y = np.array(raw_data[57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test examples\n",
    "\n",
    "# example = [0,0,0,0,0,0,0,0,0,0,0,0,0,0.85,0,0,0,0,0.85,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.126,0,0,0,0,3.925,51,106]\n",
    "example = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1.57,0,0,0,0,0.78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.184,0,8.161,31,253]\n",
    "# print(len(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Using Linear Regression: 0.5723034491347803\n",
      "[0.47398099]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## Linear Reg classifier\n",
    "\n",
    "classifier = LinearRegression()\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=50)\n",
    "linear_clf = Pipeline([('clf', classifier)])\n",
    "\n",
    "linear_clf.fit(x_train, y_train)\n",
    "y_pred = linear_clf.predict(x_test)\n",
    "\n",
    "acc_Linreg = linear_clf.score(x_test, y_test)\n",
    "print(\"Accuracy Using Linear Regression:\", acc_Linreg)\n",
    "\n",
    "print(linear_clf.predict([example]))\n",
    "print(predict_binary(linear_clf.predict([example])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using SVC: 0.9501084598698482\n",
      "[1]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "## SVC classifier\n",
    "\n",
    "classifier = LinearSVC(dual=False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=50)\n",
    "SVC_clf = Pipeline([('clf', classifier)])\n",
    "\n",
    "SVC_clf.fit(x_train, y_train)\n",
    "y_pred = SVC_clf.predict(x_test)\n",
    "\n",
    "acc_SVC = SVC_clf.score(x_test, y_test)\n",
    "print(\"Accuracy using SVC:\", acc_SVC)\n",
    "\n",
    "print(SVC_clf.predict([example]))\n",
    "print(predict_binary(SVC_clf.predict([example])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using KNN: 0.7982646420824295\n",
      "[1]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "## KNN classifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=50)\n",
    "\n",
    "KNN_clf = Pipeline([('clf', classifier)])\n",
    "\n",
    "KNN_clf.fit(x_train, y_train)\n",
    "y_pred = KNN_clf.predict(x_test)\n",
    "\n",
    "acc_KNN = KNN_clf.score(x_test, y_test)\n",
    "print(\"Accuracy using KNN:\", acc_KNN)\n",
    "\n",
    "print(KNN_clf.predict([example]))\n",
    "print(predict_binary(KNN_clf.predict([example])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading sample emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading samples\n",
    "\n",
    "f1 = open('Sample_Emails/spam_or_no_spam.txt', 'r')\n",
    "sample_mail_1 = f1.read()\n",
    "\n",
    "f2 = open('Sample_Emails/spam_or_no_spam_2.txt', 'r')\n",
    "sample_mail_2 = f2.read()\n",
    "\n",
    "f3 = open('Sample_Emails/spam_or_no_spam_3.txt', 'r')\n",
    "sample_mail_3 = f3.read()\n",
    "\n",
    "# print(sample_mail_1)\n",
    "# print(sample_mail_2)\n",
    "# print(sample_mail_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['make', 'address', 'all', '3d', 'our', 'over', 'remove', 'internet', 'order', 'mail', 'receive', 'will', 'people', 'report', 'addresses', 'free', 'business', 'email', 'you', 'credit', 'your', 'font', '000', 'money', 'hp', 'hpl', 'george', '650', 'lab', 'labs', 'telnet', '857', 'data', '415', '85', 'technology', '1999', 'parts', 'pm', 'direct', 'cs', 'meeting', 'original', 'project', 're', 'edu', 'table', 'conference']\n",
    "char = [';', '(', '[', '!', '$', '#']\n",
    "\n",
    "# print(len(words))\n",
    "# print(len(char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function returning array of attributes (without last prediction class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function returning array of attributes (without last prediction attribute)\n",
    "\n",
    "def return_attributes(name_of_input_file):\n",
    "    \n",
    "    output_arr = np.zeros(0)\n",
    "    \n",
    "    tokens = [t for t in name_of_input_file.split()]\n",
    "    total_no_tokens = (len(tokens))\n",
    "\n",
    "    total_no_chars = len(name_of_input_file)\n",
    "\n",
    "    ## For 48 attributes \n",
    "    words_freq = np.zeros(len(words)) # creating numpy array for storing freq of words\n",
    "    words_freq_perc = np.zeros(len(words)) # creating numpy array for stroing percentage of frequency of words\n",
    "\n",
    "    for token in tokens:\n",
    "        if token.lower() in words:\n",
    "            words_freq[words.index(token.lower())] += 1 # add 1 to freq\n",
    "\n",
    "    for idx, single_word_freq in enumerate(words_freq):\n",
    "        words_freq_perc[idx] = (100*single_word_freq)/total_no_tokens #### OUT 1 ####\n",
    "    \n",
    "    ## For 6 attributes \n",
    "    char_freq = np.zeros(len(char))\n",
    "    char_freq_perc = np.zeros(len(char))\n",
    "    for token in tokens:\n",
    "        for ind_char in token:\n",
    "            if ind_char in char:\n",
    "                char_freq[char.index(ind_char)] += 1\n",
    "\n",
    "    for idx, single_char_freq in enumerate(char_freq):\n",
    "        char_freq_perc[idx] = (100*single_char_freq)/total_no_chars #### OUT 2 ####\n",
    "    \n",
    "\n",
    "    ## For Capital Letters \n",
    "    all_capital_letters = re.findall(r\"[A-Z]+\", name_of_input_file)\n",
    "\n",
    "    sum_len_capital_arr = np.zeros(1)\n",
    "    sum_len_capital = 0\n",
    "    for capital_letter in all_capital_letters:\n",
    "        temp = (len(capital_letter))\n",
    "        sum_len_capital += temp\n",
    "    sum_len_capital_arr[0] = sum_len_capital #### OUT 5 ####\n",
    "\n",
    "    len_longest_seq_capital = np.zeros(1)\n",
    "    longest_seq_capital = max(all_capital_letters, key=len)\n",
    "    len_longest_seq_capital[0] = len(longest_seq_capital) #### OUT 4 ###\n",
    "\n",
    "    avg_leng = np.zeros(1)\n",
    "    avg_leng[0] = sum_len_capital/len(all_capital_letters) #### OUT 3 ###\n",
    "\n",
    "    output_arr = np.zeros(0)\n",
    "    output_arr = np.concatenate([words_freq_perc, char_freq_perc, avg_leng, len_longest_seq_capital, sum_len_capital_arr], axis=0)\n",
    "    \n",
    "#     last_attr = np.zeros(1) #### OUT 6 ####\n",
    "#     last_attr[0] = predict_binary(SVC_clf.predict([temp_output_arr]))\n",
    "#     output_arr = np.concatenate([words_freq_perc, char_freq_perc, avg_leng, len_longest_seq_capital, sum_len_capital_arr, last_attr], axis=0)\n",
    "    \n",
    "    return output_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all Attributes (57 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          1.09289617\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.54644809  0.          0.54644809  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.1980198   0.1980198   0.0660066   0.          0.0660066\n",
      "  1.16666667  2.         56.        ]\n",
      "len = 57\n"
     ]
    }
   ],
   "source": [
    "## for 'spam_or_no_spam.txt' doc\n",
    "\n",
    "only_attributes_1 = return_attributes(sample_mail_1)\n",
    "print(only_attributes_1)\n",
    "print(\"len =\",len(only_attributes_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          3.44827586\n",
      "  1.72413793  0.          1.72413793  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  1.36363636  5.         45.        ]\n",
      "len = 57\n"
     ]
    }
   ],
   "source": [
    "## for 'spam_or_no_spam_2.txt' doc\n",
    "\n",
    "only_attributes_2 = return_attributes(sample_mail_2)\n",
    "print(only_attributes_2)\n",
    "print(\"len =\",len(only_attributes_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.81967213  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          3.27868852  0.\n",
      "  0.81967213  0.          1.63934426  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.81967213  0.          0.          0.          0.\n",
      "  0.12210012  0.12210012  0.          0.          0.          0.\n",
      "  1.65714286 10.         58.        ]\n",
      "len = 57\n"
     ]
    }
   ],
   "source": [
    "## for 'spam_or_no_spam_3.txt' doc\n",
    "\n",
    "only_attributes_3 = return_attributes(sample_mail_3)\n",
    "print(only_attributes_3)\n",
    "print(\"len =\",len(only_attributes_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Extracted Attributes + prediction spam or not spam to Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_1 = open(\"only_all_attributes.txt\", \"w+\")\n",
    "out_file_1.write(str(only_attributes_1))\n",
    "out_file_1.write('\\n')\n",
    "out_file_1.write(str(only_attributes_2))\n",
    "out_file_1.write('\\n')\n",
    "out_file_1.write(str(only_attributes_3))\n",
    "out_file_1.write('\\n')\n",
    "out_file_1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Returning Array of Attributes (including last spam or not spam prediction class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function returning array of complete attributes + spam or not spam prediction class\n",
    "\n",
    "def return_comp_attributes(name_of_input_file):\n",
    "    \n",
    "    output_arr = np.zeros(0)\n",
    "    \n",
    "    tokens = [t for t in name_of_input_file.split()]\n",
    "    total_no_tokens = (len(tokens))\n",
    "\n",
    "    total_no_chars = len(name_of_input_file)\n",
    "\n",
    "    ## For 48 attributes \n",
    "    words_freq = np.zeros(len(words)) # creating numpy array for storing freq of words\n",
    "    words_freq_perc = np.zeros(len(words)) # creating numpy array for stroing percentage of frequency of words\n",
    "            \n",
    "    for token in tokens:\n",
    "        if token.lower() in words:\n",
    "            words_freq[words.index(token.lower())] += 1 # add 1 to freq\n",
    "\n",
    "    for idx, single_word_freq in enumerate(words_freq):\n",
    "        words_freq_perc[idx] = (100*single_word_freq)/total_no_tokens #### OUT 1 ####\n",
    "    \n",
    "    ## For 6 attributes \n",
    "    char_freq = np.zeros(len(char))\n",
    "    char_freq_perc = np.zeros(len(char))\n",
    "    for token in tokens:\n",
    "        for ind_char in token:\n",
    "            if ind_char in char:\n",
    "                char_freq[char.index(ind_char)] += 1\n",
    "\n",
    "    for idx, single_char_freq in enumerate(char_freq):\n",
    "        char_freq_perc[idx] = (100*single_char_freq)/total_no_chars #### OUT 2 ####\n",
    "    \n",
    "\n",
    "    ## For Capital Letters \n",
    "    all_capital_letters = re.findall(r\"[A-Z]+\", name_of_input_file)\n",
    "\n",
    "    sum_len_capital_arr = np.zeros(1)\n",
    "    sum_len_capital = 0\n",
    "    for capital_letter in all_capital_letters:\n",
    "        temp = (len(capital_letter))\n",
    "        sum_len_capital += temp\n",
    "    sum_len_capital_arr[0] = sum_len_capital #### OUT 5 ####\n",
    "\n",
    "    len_longest_seq_capital = np.zeros(1)\n",
    "    longest_seq_capital = max(all_capital_letters, key=len)\n",
    "    len_longest_seq_capital[0] = len(longest_seq_capital) #### OUT 4 ###\n",
    "\n",
    "    avg_leng = np.zeros(1)\n",
    "    avg_leng[0] = sum_len_capital/len(all_capital_letters) #### OUT 3 ###\n",
    "\n",
    "    temp_output_arr = np.zeros(0)\n",
    "    temp_output_arr = np.concatenate([words_freq_perc, char_freq_perc, avg_leng, len_longest_seq_capital, sum_len_capital_arr], axis=0)\n",
    "    \n",
    "    ## Prediction Attribute (final attribute) using SVC classifier\n",
    "    last_attr = np.zeros(1) #### OUT 6 ####\n",
    "    last_attr[0] = predict_binary(SVC_clf.predict([temp_output_arr]))\n",
    "    output_arr = np.concatenate([words_freq_perc, char_freq_perc, avg_leng, len_longest_seq_capital, sum_len_capital_arr, last_attr], axis=0)\n",
    "    \n",
    "    return output_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all Attributes + last column of Spam or Not Spam prediction (57+1=58 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          1.09289617\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.54644809  0.          0.54644809  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.1980198   0.1980198   0.0660066   0.          0.0660066\n",
      "  1.16666667  2.         56.          0.        ]\n",
      "len = 58\n"
     ]
    }
   ],
   "source": [
    "## for 'spam_or_no_spam.txt' doc\n",
    "\n",
    "attributes_1 = return_comp_attributes(sample_mail_1)\n",
    "print(attributes_1)\n",
    "print(\"len =\",len(attributes_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          3.44827586\n",
      "  1.72413793  0.          1.72413793  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  1.36363636  5.         45.          0.        ]\n",
      "len = 58\n"
     ]
    }
   ],
   "source": [
    "## for 'spam_or_no_spam_2.txt' doc\n",
    "\n",
    "attributes_2 = return_comp_attributes(sample_mail_2)\n",
    "print(attributes_2)\n",
    "print(\"len =\",len(attributes_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.81967213  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          3.27868852  0.\n",
      "  0.81967213  0.          1.63934426  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.81967213  0.          0.          0.          0.\n",
      "  0.12210012  0.12210012  0.          0.          0.          0.\n",
      "  1.65714286 10.         58.          1.        ]\n",
      "len = 58\n"
     ]
    }
   ],
   "source": [
    "## for 'spam_or_no_spam_3.txt' doc\n",
    "\n",
    "attributes_3 = return_comp_attributes(sample_mail_3)\n",
    "print(attributes_3)\n",
    "print(\"len =\",len(attributes_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Extracted Attributes + prediction spam or not spam to Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_2 = open(\"attributes+prediction_output.txt\", \"w+\")\n",
    "out_file_2.write(str(attributes_1))\n",
    "out_file_2.write('\\n')\n",
    "out_file_2.write(str(attributes_2))\n",
    "out_file_2.write('\\n')\n",
    "out_file_2.write(str(attributes_3))\n",
    "out_file_2.write('\\n')\n",
    "out_file_2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Different Classifiers on Given Example Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'spam_or_no_spam.txt':\n",
      "Using Linear Regression Classifier: 0\n",
      "Using SVC Classifier: 0\n",
      "Using KNN Classifier: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"For 'spam_or_no_spam.txt':\")\n",
    "print(\"Using Linear Regression Classifier:\", predict_binary(linear_clf.predict([return_attributes(sample_mail_1)])))\n",
    "print(\"Using SVC Classifier:\", predict_binary(SVC_clf.predict([return_attributes(sample_mail_1)])))\n",
    "print(\"Using KNN Classifier:\", predict_binary(KNN_clf.predict([return_attributes(sample_mail_1)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'spam_or_no_spam_2.txt':\n",
      "Using Linear Regression Classifier: 0\n",
      "Using SVC Classifier: 0\n",
      "Using KNN Classifier: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"For 'spam_or_no_spam_2.txt':\")\n",
    "print(\"Using Linear Regression Classifier:\", predict_binary(linear_clf.predict([return_attributes(sample_mail_2)])))\n",
    "print(\"Using SVC Classifier:\", predict_binary(SVC_clf.predict([return_attributes(sample_mail_2)])))\n",
    "print(\"Using KNN Classifier:\", predict_binary(KNN_clf.predict([return_attributes(sample_mail_2)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'spam_or_no_spam_3.txt':\n",
      "Using Linear Regression Classifier: 0\n",
      "Using SVC Classifier: 1\n",
      "Using KNN Classifier: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"For 'spam_or_no_spam_3.txt':\")\n",
    "print(\"Using Linear Regression Classifier:\", predict_binary(linear_clf.predict([return_attributes(sample_mail_3)])))\n",
    "print(\"Using SVC Classifier:\", predict_binary(SVC_clf.predict([return_attributes(sample_mail_3)])))\n",
    "print(\"Using KNN Classifier:\", predict_binary(KNN_clf.predict([return_attributes(sample_mail_3)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Random Mail file: 'spam_try.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear Regression Classifier: 1\n",
      "Using SVC Classifier: 1\n",
      "Using KNN Classifier: 0\n"
     ]
    }
   ],
   "source": [
    "f4 = open('Sample_Emails/spam_try.txt', 'r')\n",
    "sample_mail_4 = f4.read()\n",
    "attributes_4 = return_attributes(sample_mail_4)\n",
    "\n",
    "print(\"Using Linear Regression Classifier:\", predict_binary(linear_clf.predict([attributes_4])))\n",
    "print(\"Using SVC Classifier:\", predict_binary(SVC_clf.predict([attributes_4])))\n",
    "print(\"Using KNN Classifier:\", predict_binary(KNN_clf.predict([attributes_4])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
